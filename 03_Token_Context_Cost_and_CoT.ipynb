{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69f9f7c8",
      "metadata": {
        "id": "69f9f7c8"
      },
      "source": [
        "# Notebook 3 — Token/Context Cost + CoT (Quality and Cost)\n",
        "\n",
        "\n",
        "1) Zero/One/Few-shot prompting consume of token\n",
        "2) CoT (step-by-step) cost / output relation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VQKT-Kn_cnjl"
      },
      "id": "VQKT-Kn_cnjl"
    },
    {
      "cell_type": "markdown",
      "id": "d8b8bf97",
      "metadata": {
        "id": "d8b8bf97"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Azure openai gpt model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a359e34",
      "metadata": {
        "id": "4a359e34",
        "outputId": "eaf4d23d-9c4e-4696-817c-def950d47bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Requirements\n",
        "%pip -q install -U langchain-core langchain-openai langchain-google-genai tiktoken python-dotenv matplotlib pandas==2.2.2 pydantic==2.12.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d3492d",
      "metadata": {
        "id": "b5d3492d",
        "outputId": "97d3a206-091a-4077-e5d8-33671ca2e29c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM ready: Azure OpenAI (vodafone_rag_module)\n"
          ]
        }
      ],
      "source": [
        "import os, json, re\n",
        "from typing import Dict, Any\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "# --- Azure OpenAI Configuration ---\n",
        "AZURE_ENDPOINT = \"https://sd-rg.cognitiveservices.azure.com/\"\n",
        "AZURE_API_KEY = \"\"  # api key\n",
        "AZURE_DEPLOYMENT = \"vodafone_rag_module\"\n",
        "API_VERSION = \"2024-12-01-preview\"\n",
        "\n",
        "def get_llm():\n",
        "    \"\"\"\n",
        "    Initializes the Azure OpenAI client using the provided configuration.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (llm_instance, provider_name_string)\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If API credentials are missing or connection fails.\n",
        "    \"\"\"\n",
        "    # Check if essential credentials are present\n",
        "    if AZURE_API_KEY and AZURE_ENDPOINT:\n",
        "        try:\n",
        "            llm = AzureChatOpenAI(\n",
        "                azure_deployment=AZURE_DEPLOYMENT,\n",
        "                api_version=API_VERSION,\n",
        "                azure_endpoint=AZURE_ENDPOINT,\n",
        "                api_key=AZURE_API_KEY,\n",
        "                temperature=0.1,\n",
        "                max_retries=2\n",
        "            )\n",
        "            return llm, f'Azure OpenAI ({AZURE_DEPLOYMENT})'\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Azure connection error: {e}\")\n",
        "\n",
        "    raise RuntimeError('Azure API credentials are missing!')\n",
        "\n",
        "# --- Initialization ---\n",
        "try:\n",
        "    llm, provider = get_llm()\n",
        "    print('✅ LLM ready:', provider)\n",
        "\n",
        "    # Uncomment the line below to test the connection immediately\n",
        "    # print(\"Test Response:\", llm.invoke(\"Hello, are you active?\").content)\n",
        "\n",
        "except Exception as e:\n",
        "    # If initialization fails, set llm to None to prevent subsequent NameErrors\n",
        "    llm = None\n",
        "    print(f\"❌ Error occurred: {e}\")\n",
        "\n",
        "def llm_text(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends a prompt to the LLM and retrieves the text response.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The input string to send to the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The clean text response from the model.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        return \"Error: LLM is not initialized.\"\n",
        "\n",
        "    resp = llm.invoke(prompt)\n",
        "    # Safely retrieve content whether it's an object or string\n",
        "    return getattr(resp, 'content', str(resp)).strip()\n",
        "\n",
        "def strip_fences(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes Markdown code fences (e.g., ```json ... ```) from a string.\n",
        "\n",
        "    Args:\n",
        "        s (str): The input string containing code fences.\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned string without the fences.\n",
        "    \"\"\"\n",
        "    s = s.strip()\n",
        "    # Remove starting ```json or ``` (case insensitive)\n",
        "    s = re.sub(r'^```(json)?\\s*', '', s, flags=re.IGNORECASE)\n",
        "    # Remove ending ```\n",
        "    s = re.sub(r'\\s*```$', '', s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2dca12",
      "metadata": {
        "id": "ca2dca12",
        "outputId": "698e144a-afb1-4eda-f4f3-794a1c724817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Dataset for Triage\n",
        "EMAILS = [\n",
        "    {'id': 'E1', 'text': 'Kargom hâlâ gelmedi. 7 gündür bekliyorum. Acil çözüm istiyorum!', 'notes': 'Gecikme + yüksek aciliyet'},\n",
        "    {'id': 'E2', 'text': 'Ürün kırık geldi. Değişim yapabilir miyiz?', 'notes': 'Hasarlı ürün'},\n",
        "    {'id': 'E3', 'text': 'İade sürecini nasıl başlatabilirim? Kutuyu attım ama ürün duruyor.', 'notes': 'İade + edge-case (kutusuz)'},\n",
        "    {'id': 'E4', 'text': 'Kartımdan iki kez çekim yapılmış görünüyor. Lütfen hemen kontrol edin.', 'notes': 'Faturalama + yüksek aciliyet'},\n",
        "    {'id': 'E5', 'text': 'Ürününüzün kullanım kılavuzunu paylaşır mısınız?', 'notes': 'Bilgi talebi (low)'},\n",
        "]\n",
        "len(EMAILS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c91e1dd",
      "metadata": {
        "id": "1c91e1dd"
      },
      "source": [
        "## 1) Token Counting\n",
        "\n",
        "For OpenAI, `tiktoken` gives a more accurate count. Tokenizers may differ for other providers. Here:\n",
        "- It uses `tiktoken` if it works\n",
        "- It makes an approximate estimate if it doesn't work (1 token ≈ 4 characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289ac94d",
      "metadata": {
        "id": "289ac94d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_tokens(text: str, model_hint: str = 'gpt-4o-mini') -> int:\n",
        "    try:\n",
        "        import tiktoken\n",
        "        enc = tiktoken.encoding_for_model(model_hint)\n",
        "        return len(enc.encode(text))\n",
        "    except Exception:\n",
        "        return max(1, len(text) // 4)\n",
        "\n",
        "def estimate_cost(tokens_in: int, tokens_out: int, price_in_per_1k: float, price_out_per_1k: float) -> float:\n",
        "    return (tokens_in/1000)*price_in_per_1k + (tokens_out/1000)*price_out_per_1k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2178ad9c",
      "metadata": {
        "id": "2178ad9c"
      },
      "source": [
        "## 2) Difference of Three strategy token size\n",
        "\n",
        "From Notebook 1 schema and examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f88460a",
      "metadata": {
        "id": "1f88460a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "SCHEMA = (\n",
        "    'Return ONLY valid JSON with exactly these keys:\\n'\n",
        "    '{\\n'\n",
        "    '  \"category\": \"string\",\\n'\n",
        "    '  \"urgency\": \"low|medium|high\",\\n'\n",
        "    '  \"reason\": \"string (max 1 sentence)\"\\n'\n",
        "    '}\\n'\n",
        "    'No extra text, no markdown, JSON only.'\n",
        ")\n",
        "\n",
        "ONE_EXAMPLE = {\n",
        "    'email': 'My order arrived broken. I want a replacement as soon as possible.',\n",
        "    'answer': {'category':'Damaged product','urgency':'medium','reason':'Customer reports a damaged item and requests a replacement.'}\n",
        "}\n",
        "\n",
        "FEW_EXAMPLES = [\n",
        "    ('Where is my package? It was supposed to arrive 5 days ago.', {'category':'Delivery issue','urgency':'high','reason':'Customer reports a significantly delayed delivery.'}),\n",
        "    ('How can I return the product? I changed my mind.', {'category':'Return request','urgency':'low','reason':'Customer asks for return instructions without a critical issue.'}),\n",
        "    ('You charged me twice for the same order. Fix this immediately.', {'category':'Billing issue','urgency':'high','reason':'Customer reports a double charge and requests urgent resolution.'}),\n",
        "]\n",
        "\n",
        "def prompt_zero(email_text: str) -> str:\n",
        "    return ('You are a customer support triage assistant.\\n'\n",
        "            'Classify the email into a category and urgency.\\n\\n' + SCHEMA + '\\n\\n' + 'Email:\\n' + email_text)\n",
        "\n",
        "def prompt_one(email_text: str) -> str:\n",
        "    return ('You are a customer support triage assistant.\\n'\n",
        "            'Use the example to follow the same output format and labeling style.\\n\\n'\n",
        "            + SCHEMA + '\\n\\n'\n",
        "            + 'Example:\\nEmail:\\n' + ONE_EXAMPLE['email'] + '\\n'\n",
        "            + 'Answer:\\n' + json.dumps(ONE_EXAMPLE['answer'], ensure_ascii=False) + '\\n\\n'\n",
        "            + 'Now classify this email:\\n\\nEmail:\\n' + email_text)\n",
        "\n",
        "def prompt_few(email_text: str) -> str:\n",
        "    ex_block = ''\n",
        "    for mail, ans in FEW_EXAMPLES:\n",
        "        ex_block += 'Email:\\n' + mail + '\\nAnswer:\\n' + json.dumps(ans, ensure_ascii=False) + '\\n\\n'\n",
        "    return ('You are a customer support triage assistant.\\n'\n",
        "            'Follow the same pattern as the examples.\\n\\n' + SCHEMA + '\\n\\n'\n",
        "            + 'Examples:\\n' + ex_block\n",
        "            + 'Now classify this email:\\n\\nEmail:\\n' + email_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6375d67d",
      "metadata": {
        "id": "6375d67d"
      },
      "source": [
        "### Token Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479e4e94",
      "metadata": {
        "id": "479e4e94",
        "outputId": "6f049259-f2df-49e3-cab9-1642a4358fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    strategy  prompt_tokens\n",
              "0  zero-shot             97\n",
              "1   one-shot            155\n",
              "2   few-shot            238"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9e89cb2-a916-442d-9f04-e8c92c002992\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strategy</th>\n",
              "      <th>prompt_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero-shot</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one-shot</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e89cb2-a916-442d-9f04-e8c92c002992')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9e89cb2-a916-442d-9f04-e8c92c002992 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9e89cb2-a916-442d-9f04-e8c92c002992');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"zero-shot\",\n          \"one-shot\",\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 97,\n        \"max\": 238,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          97,\n          155,\n          238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample = EMAILS[0]['text']\n",
        "model_hint = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
        "\n",
        "p0, p1, p2 = prompt_zero(sample), prompt_one(sample), prompt_few(sample)\n",
        "t0, t1, t2 = count_tokens(p0, model_hint), count_tokens(p1, model_hint), count_tokens(p2, model_hint)\n",
        "\n",
        "pd.DataFrame([\n",
        "    {'strategy':'zero-shot', 'prompt_tokens': t0},\n",
        "    {'strategy':'one-shot',  'prompt_tokens': t1},\n",
        "    {'strategy':'few-shot',  'prompt_tokens': t2},\n",
        "]).sort_values('prompt_tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33bd53f2",
      "metadata": {
        "id": "33bd53f2"
      },
      "source": [
        "## 3) Simulation of cost\n",
        "\n",
        "This price is estimated, 1M input token approxiametly $0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb75f380",
      "metadata": {
        "id": "cb75f380",
        "outputId": "209807ef-8bb4-41fb-a328-47b6acab249b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    strategy  prompt_tokens_in  avg_tokens_out  est_cost_per_call\n",
              "0  zero-shot                97              90               2.77\n",
              "1   one-shot               155              90               3.35\n",
              "2   few-shot               238              90               4.18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97d28d5a-4bf0-4467-b5b6-5438fb22ee9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strategy</th>\n",
              "      <th>prompt_tokens_in</th>\n",
              "      <th>avg_tokens_out</th>\n",
              "      <th>est_cost_per_call</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero-shot</td>\n",
              "      <td>97</td>\n",
              "      <td>90</td>\n",
              "      <td>2.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one-shot</td>\n",
              "      <td>155</td>\n",
              "      <td>90</td>\n",
              "      <td>3.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>238</td>\n",
              "      <td>90</td>\n",
              "      <td>4.18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97d28d5a-4bf0-4467-b5b6-5438fb22ee9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97d28d5a-4bf0-4467-b5b6-5438fb22ee9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97d28d5a-4bf0-4467-b5b6-5438fb22ee9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"zero-shot\",\n          \"one-shot\",\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_tokens_in\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 97,\n        \"max\": 238,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          97,\n          155,\n          238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_tokens_out\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 90,\n        \"max\": 90,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"est_cost_per_call\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7086842268128545,\n        \"min\": 2.7699999999999996,\n        \"max\": 4.18,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.7699999999999996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "price_in_per_1k  = 10   # örn: 0.15\n",
        "price_out_per_1k = 20   # örn: 0.60\n",
        "avg_out_tokens   = 90\n",
        "\n",
        "rows = []\n",
        "for name, tok in [('zero-shot', t0), ('one-shot', t1), ('few-shot', t2)]:\n",
        "    rows.append({\n",
        "        'strategy': name,\n",
        "        'prompt_tokens_in': tok,\n",
        "        'avg_tokens_out': avg_out_tokens,\n",
        "        'est_cost_per_call': estimate_cost(tok, avg_out_tokens, price_in_per_1k, price_out_per_1k)\n",
        "    })\n",
        "pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05e2601",
      "metadata": {
        "id": "a05e2601"
      },
      "source": [
        "## 4) Context overloading ( as the sample size increases )\n",
        "\n",
        "How does the prompt token grow when the number of few-shot samples is increased?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ad6095",
      "metadata": {
        "id": "75ad6095",
        "outputId": "428004f2-c13d-4c7c-9279-11cc76b14759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n= 0  prompt_tokens≈102\n",
            "n= 1  prompt_tokens≈147\n",
            "n= 3  prompt_tokens≈238\n",
            "n= 5  prompt_tokens≈328\n",
            "n=10  prompt_tokens≈555\n",
            "n=20  prompt_tokens≈1008\n",
            "n=40  prompt_tokens≈1915\n"
          ]
        }
      ],
      "source": [
        "def prompt_with_n_examples(email_text: str, n: int) -> str:\n",
        "    exs = (FEW_EXAMPLES * ((n // len(FEW_EXAMPLES)) + 1))[:n]\n",
        "    ex_block = ''\n",
        "    for mail, ans in exs:\n",
        "        ex_block += 'Email:\\n' + mail + '\\nAnswer:\\n' + json.dumps(ans, ensure_ascii=False) + '\\n\\n'\n",
        "    return ('You are a customer support triage assistant.\\n'\n",
        "            'Follow the same pattern as the examples.\\n\\n' + SCHEMA + '\\n\\n'\n",
        "            + 'Examples:\\n' + ex_block\n",
        "            + 'Now classify this email:\\n\\nEmail:\\n' + email_text)\n",
        "\n",
        "for n in [0, 1, 3, 5, 10, 20, 40]:\n",
        "    p = prompt_with_n_examples(sample, n)\n",
        "    print(f'n={n:>2}  prompt_tokens≈{count_tokens(p, model_hint)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc4d9715",
      "metadata": {
        "id": "fc4d9715"
      },
      "source": [
        "## 5) CoT (Chain-of-Thought): kalite vs maliyet\n",
        "\n",
        "Burada iki yaklaşımı karşılaştırıyoruz:\n",
        "- **Direct**: sadece sonucu üret\n",
        "- **Step-by-step**: adım adım çöz\n",
        "\n",
        "> Üretimde full CoT’yi kullanıcıya göstermek istemeyebilirsiniz. Alternatif: kısa gerekçe + self-check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f00a91",
      "metadata": {
        "id": "b1f00a91"
      },
      "outputs": [],
      "source": [
        "MATH_TASK = ('A company sold 120 items on Monday, 95 on Tuesday, and 110 on Wednesday. '\n",
        "             'If 15 items were returned, how many net items were sold?')\n",
        "\n",
        "PROMPT_DIRECT = 'Answer with a single line: \"Net sold = <number>\". Question: ' + MATH_TASK\n",
        "PROMPT_COT    = 'Solve step by step, then answer with a single line: \"Net sold = <number>\". Question: ' + MATH_TASK\n",
        "\n",
        "direct = llm_text(PROMPT_DIRECT)\n",
        "cot    = llm_text(PROMPT_COT)\n",
        "\n",
        "print('DIRECT:\\n', direct)\n",
        "print('\\nCOT:\\n', cot)\n",
        "\n",
        "print('\\nToken estimates (prompt only):')\n",
        "print('direct:', count_tokens(PROMPT_DIRECT, model_hint))\n",
        "print('cot   :', count_tokens(PROMPT_COT, model_hint))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f755a0",
      "metadata": {
        "id": "75f755a0"
      },
      "source": [
        "## 6) Alternatif: brief rationale + self-check\n",
        "\n",
        "CoT yerine, üretimde daha güvenli ve kısa bir format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8371ebd4",
      "metadata": {
        "id": "8371ebd4"
      },
      "outputs": [],
      "source": [
        "PROMPT_BRIEF = (\n",
        "    'Return:\\n'\n",
        "    '1) Answer: Net sold = <number>\\n'\n",
        "    '2) Rationale: (max 2 sentences)\\n'\n",
        "    '3) Self-check: (max 2 bullets)\\n\\n'\n",
        "    'Question: ' + MATH_TASK\n",
        ")\n",
        "\n",
        "brief = llm_text(PROMPT_BRIEF)\n",
        "print(brief)\n",
        "print('\\nPrompt token estimate:', count_tokens(PROMPT_BRIEF, model_hint))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd84cff2",
      "metadata": {
        "id": "cd84cff2"
      },
      "source": [
        "## 7) Egzersiz (3–5 dk)\n",
        "\n",
        "1) CoT prompt’unu Türkçe yapıp token sayımını kıyaslayın.\n",
        "2) 10–20 örneğe çıkınca context’in nasıl şiştiğini not edin.\n",
        "3) Brief + self-check formatını farklı bir problemde deneyin."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}